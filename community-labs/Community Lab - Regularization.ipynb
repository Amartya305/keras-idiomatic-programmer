{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google LLC\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/keras-idiomatic-programmer/blob/master/community-labs/Community Lab - Regularization.ipynb\">\n",
    "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "\n",
    "For best performance using Colab, once the notebook is launched, from dropdown menu select **Runtime -> Change Runtime Type**, and select **GPU** for **Hardware Accelerator**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composable \"Design Pattern\" for AutoML friendly models\n",
    "\n",
    "## Community Lab 2: Using Regularization to Tackle Overfitting\n",
    "\n",
    "### Objective\n",
    "\n",
    "Prior success for training models for high accuracy was to use large models. Today, we believe the success of large models is due to the fact that they are a collection of sub-models, and one of the sub-models is the winning model (lottery ticket hypothesis).\n",
    "\n",
    "Today, we try to train compact size models. One of the challenges in such a model is the training data may \"fit\" itself to the model's weights, and not generalize to the validation/test data.\n",
    "\n",
    "In this lab, we will explore methods of regularization and learning rates to prevent the training data from \"fitting\" to the weights in a compact model -- without use of historical methods such as dropout or data augmentation.\n",
    "\n",
    "*Question*: Can we generalize a compact model without image augmentation?\n",
    "\n",
    "*Question*: How is training time effected?\n",
    "\n",
    "*Question*: How small can a compact model be made and maintain accuracy on the validation/test data?\n",
    "\n",
    "### Approach\n",
    "\n",
    "We will use the composable design pattern, and prebuilt units from the Google Cloud AI Developer Relations repo: [Model Zoo](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo)\n",
    "\n",
    "If you are not familiar with the Composable design pattern, we recommemd you review the [ResNet](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo/resnet) model in our zoo.\n",
    "\n",
    "We recommend a constant set for hyperparameters, where batch_size is 32 and initial learning rate is 0.001 -- but you may use any value for hyperparameters you prefer.\n",
    "\n",
    "We will use the metaparameters feature in the composable design pattern for the macro architecture search -- sort of a 'human assisted AutoML'.\n",
    "\n",
    "\n",
    "### Reporting Findings\n",
    "\n",
    "You can contact us on your findings via the twitter account: @andrewferlitsch\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this notebook, we use the CIFAR-10 datasets which consist of images 32x32x3 for 10 classes -- but you may use any dataset you prefer.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Build a baseline (reference) model for CIFAR-10 with no regularization.\n",
    "\n",
    "2. Add regularization to the classifier (softmax) layer by adding Guassian noise.\n",
    "\n",
    "3. Add a large and small amounts of L2 regularization to convolutional and dense layers' weights.\n",
    "\n",
    "4. Compare the results of different magnitudes of layer regularization.\n",
    "\n",
    "5. Train with a two-tier learning rate schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, Add, Dense, GaussianNoise\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dataset\n",
    "\n",
    "Load the dataset into memory as numpy arrays, and then normalize the image data (preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = (x_train / 255.0).astype(np.float32)\n",
    "x_test  = (x_test / 255.0).astype(np.float32)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Baseline Model for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet/resnet_v2_c.py\n",
    "\n",
    "class ResNetV2(object):\n",
    "    \"\"\" Construct a Residual Convolution Network Network V2 \"\"\"\n",
    "    # Meta-parameter: list of groups: number of filters and number of blocks\n",
    "    groups = { 50 : [ { 'n_filters' : 64, 'n_blocks': 3 },\n",
    "                      { 'n_filters': 128, 'n_blocks': 4 },\n",
    "                      { 'n_filters': 256, 'n_blocks': 6 },\n",
    "                      { 'n_filters': 512, 'n_blocks': 3 } ],            # ResNet50\n",
    "               101: [ { 'n_filters' : 64, 'n_blocks': 3 },\n",
    "                      { 'n_filters': 128, 'n_blocks': 4 },\n",
    "                      { 'n_filters': 256, 'n_blocks': 23 },\n",
    "                      { 'n_filters': 512, 'n_blocks': 3 } ],            # ResNet101\n",
    "               152: [ { 'n_filters' : 64, 'n_blocks': 3 },\n",
    "                      { 'n_filters': 128, 'n_blocks': 8 },\n",
    "                      { 'n_filters': 256, 'n_blocks': 36 },\n",
    "                      { 'n_filters': 512, 'n_blocks': 3 } ]             # ResNet152\n",
    "             }\n",
    "    init_weights = 'he_normal'\n",
    "    reg=l2(0.001)\n",
    "    _model = None\n",
    "\n",
    "    def __init__(self, n_layers, input_shape=(224, 224, 3), n_classes=1000):\n",
    "        \"\"\" Construct a Residual Convolutional Neural Network V2\n",
    "            n_layers   : number of layers\n",
    "            input_shape: input shape\n",
    "            n_classes  : number of output classes\n",
    "        \"\"\"\n",
    "        # predefined\n",
    "        if isinstance(n_layers, int):\n",
    "            if n_layers not in [50, 101, 152]:\n",
    "                raise Exception(\"ResNet: Invalid value for n_layers\")\n",
    "            groups = self.groups[n_layers]\n",
    "        # user defined\n",
    "        else:\n",
    "            groups = n_layers\n",
    "\n",
    "        # The input tensor\n",
    "        inputs = Input(input_shape)\n",
    "\n",
    "        # The stem convolutional group\n",
    "        x = self.stem(inputs)\n",
    "\n",
    "        # The learner\n",
    "        x = self.learner(x, groups=groups)\n",
    "\n",
    "        # The classifier \n",
    "        outputs = self.classifier(x, n_classes)\n",
    "\n",
    "        # Instantiate the Model\n",
    "        self._model = Model(inputs, outputs)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, _model):\n",
    "        self._model = _model\n",
    "\n",
    "    def stem(self, inputs):\n",
    "        \"\"\" Construct the Stem Convolutional Group \n",
    "            inputs : the input vector\n",
    "        \"\"\"\n",
    "        # The 224x224 images are zero padded (black - no signal) to be 230x230 images prior to the first convolution\n",
    "        x = ZeroPadding2D(padding=(3, 3))(inputs)\n",
    "    \n",
    "        # First Convolutional layer uses large (coarse) filter\n",
    "        x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', use_bias=False, \n",
    "                   kernel_initializer=self.init_weights, kernel_regularizer=self.reg)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        # Pooled feature maps will be reduced by 75%\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "        return x\n",
    "\n",
    "    def learner(self, x, **metaparameters):\n",
    "        \"\"\" Construct the Learner\n",
    "            x     : input to the learner\n",
    "            groups: list of groups: number of filters and blocks\n",
    "        \"\"\"\n",
    "        groups = metaparameters['groups']\n",
    "\n",
    "        # First Residual Block Group (not strided)\n",
    "        x = ResNetV2.group(x, strides=(1, 1), **groups.pop(0))\n",
    "\n",
    "        # Remaining Residual Block Groups (strided)\n",
    "        for group in groups:\n",
    "            x = ResNetV2.group(x, **group)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def group(x, strides=(2, 2), init_weights=None, **metaparameters):\n",
    "        \"\"\" Construct a Residual Group\n",
    "            x         : input into the group\n",
    "            strides   : whether the projection block is a strided convolution\n",
    "            n_filters : number of filters for the group\n",
    "            n_blocks  : number of residual blocks with identity link\n",
    "        \"\"\"\n",
    "        n_blocks  = metaparameters['n_blocks']\n",
    "\n",
    "        # Double the size of filters to fit the first Residual Group\n",
    "        x = ResNetV2.projection_block(x, strides=strides, init_weights=init_weights, **metaparameters)\n",
    "\n",
    "        # Identity residual blocks\n",
    "        for _ in range(n_blocks):\n",
    "            x = ResNetV2.identity_block(x, init_weights=init_weights, **metaparameters)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def identity_block(x, init_weights=None, **metaparameters):\n",
    "        \"\"\" Construct a Bottleneck Residual Block with Identity Link\n",
    "            x        : input into the block\n",
    "            n_filters: number of filters\n",
    "            reg      : kernel regularizer\n",
    "        \"\"\"\n",
    "        n_filters = metaparameters['n_filters']\n",
    "        if 'reg' in metaparameters:\n",
    "            reg = metaparameters['reg']\n",
    "        else:\n",
    "            reg = ResNetV2.reg\n",
    "\n",
    "        if init_weights is None:\n",
    "            init_weights = ResNetV2.init_weights\n",
    "    \n",
    "        # Save input vector (feature maps) for the identity link\n",
    "        shortcut = x\n",
    "    \n",
    "        ## Construct the 1x1, 3x3, 1x1 convolution block\n",
    "    \n",
    "        # Dimensionality reduction\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(n_filters, (1, 1), strides=(1, 1), use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Bottleneck layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Dimensionality restoration - increase the number of output filters by 4X\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(n_filters * 4, (1, 1), strides=(1, 1), use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Add the identity link (input) to the output of the residual block\n",
    "        x = Add()([shortcut, x])\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def projection_block(x, strides=(2,2), init_weights=None, **metaparameters):\n",
    "        \"\"\" Construct a Bottleneck Residual Block of Convolutions with Projection Shortcut\n",
    "            Increase the number of filters by 4X\n",
    "            x        : input into the block\n",
    "            strides  : whether the first convolution is strided\n",
    "            n_filters: number of filters\n",
    "            reg      : kernel regularizer\n",
    "        \"\"\"\n",
    "        n_filters = metaparameters['n_filters']\n",
    "        if 'reg' in metaparameters:\n",
    "            reg = metaparameters['reg']\n",
    "        else:\n",
    "            reg = ResNetV2.reg\n",
    "\n",
    "        if init_weights is None:\n",
    "            init_weights = ResNetV2.init_weights\n",
    "\n",
    "        # Construct the projection shortcut\n",
    "        # Increase filters by 4X to match shape when added to output of block\n",
    "        shortcut = BatchNormalization()(x)\n",
    "        shortcut = Conv2D(4 * n_filters, (1, 1), strides=strides, use_bias=False, \n",
    "                          kernel_initializer=init_weights, kernel_regularizer=reg)(shortcut)\n",
    "\n",
    "        ## Construct the 1x1, 3x3, 1x1 convolution block\n",
    "    \n",
    "        # Dimensionality reduction\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(n_filters, (1, 1), strides=(1,1), use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Bottleneck layer\n",
    "        # Feature pooling when strides=(2, 2)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(n_filters, (3, 3), strides=strides, padding='same', use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Dimensionality restoration - increase the number of filters by 4X\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(4 * n_filters, (1, 1), strides=(1, 1), use_bias=False, \n",
    "                   kernel_initializer=init_weights, kernel_regularizer=reg)(x)\n",
    "\n",
    "        # Add the projection shortcut to the output of the residual block\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    def classifier(self, x, n_classes):\n",
    "        \"\"\" Construct the Classifier Group \n",
    "            x         : input to the classifier\n",
    "            n_classes : number of output classes\n",
    "        \"\"\"\n",
    "        # Pool at the end of all the convolutional residual blocks\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # Final Dense Outputting Layer for the outputs\n",
    "        outputs = Dense(n_classes, activation='softmax', \n",
    "                        kernel_initializer=self.init_weights, kernel_regularizer=self.reg)(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(reg=None, n_blocks=4, lr=0.001, noise=None):\n",
    "    ResNetV2.reg = reg\n",
    "    \n",
    "    # Stem\n",
    "    inputs = Input((32, 32, 3))\n",
    "    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', \n",
    "               kernel_initializer='he_normal', kernel_regularizer=reg)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Learner\n",
    "    x = ResNetV2.group(x, n_blocks=n_blocks, n_filters=16)\n",
    "    x = ResNetV2.group(x, n_blocks=n_blocks, n_filters=64)\n",
    "    x = ResNetV2.group(x, n_blocks=n_blocks, n_filters=128)\n",
    "\n",
    "    # Classifier\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    if noise:\n",
    "        x = GaussianNoise(noise)(x)\n",
    "        x = ReLU()(x)\n",
    "        \n",
    "    outputs = Dense(10, activation='softmax',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=reg)(x)\n",
    "    \n",
    "    resnet = Model(inputs, outputs)\n",
    "    resnet.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['acc'])\n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model and Tackle Overfitting\n",
    "\n",
    "This small models still has too many parameters, that the training data can't fit to the parameters. As is (after 10 epochs), the validation/test data will plateau out at ~73% accuracy, while the training accuracy has climbed to 91%. But if we reduce the size of the model, we eliminate too many parameters to increase accuracy.\n",
    "\n",
    "#### Base Model\n",
    "\n",
    "Let's first train as-is to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = makeModel()\n",
    "resnet.summary()\n",
    "resnet.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "resnet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Noise\n",
    "\n",
    "Let's try adding some noise to the input to the output classification layer. This will act as a regularizer. Note how we added a ReLU() afterwards. If we did not, some of the weights might have a negative value from the noise (as if it was a leaky ReLU).\n",
    "\n",
    "As is (after 10 epochs), the training accuracy remains unchanged, but the validation/test data has crept up a small amount to ~75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = makeModel(noise=0.1)\n",
    "resnet.summary()\n",
    "resnet.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "resnet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Regularization\n",
    "\n",
    "Let's use an aggresive form of kernel regularization -- this will penalize any large weight changes to prevent data snapping into the node (L2 regularation), but may greatly reduce the rate of learning - or learning at all (rate = 0.01). \n",
    "\n",
    "As is (after 10 epochs), the training accuracy will be plateaued around ~60%. It just won't learn at this level of aggressive layer regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = makeModel(noise=0.1, reg=l2(0.01))\n",
    "resnet.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "resnet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try less aggressive amount of regularization (reduce by a magnitude of 10). The rate of increase in training accuracy will slow down and be more stable with the validation accuracy. We can now increase the number of epochs to 30.\n",
    "\n",
    "As is (after 30 epochs), the validation/test data has crept up a modest amount to ~80%, while the training accuracy has plauteaued also around 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = makeBaseModel(noise=0.1, reg=l2(0.001))\n",
    "resnet.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=1)\n",
    "resnet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate\n",
    "\n",
    "You can see that we are plateauing out around 80% on the validation/test data after 30 epochs and the training accuracy seems to be equally plateaud. This suggests that the weight updates are bouncing back/forth trying to fit the training data; whereby, lines of linear separation are slightly shifting causing swings in the validation loss.\n",
    "\n",
    "Let's address this by dropping the learning rate a magnitude after 30 epochs, and run another 10. We can see now that the validation/test data climb and plateaus at ~84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])\n",
    "resnet.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=1)\n",
    "resnet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "Think how you can modify this experiment, to meet the objectives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
